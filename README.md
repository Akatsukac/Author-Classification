# TheClassifiers

Author verification project built to detect whether a NYT article is written by Gina Kolata. 

baseline_results.txt
- Baseline results generated by synonym based single feature system. File is formatted as 0 or 1 per line for each corresponding test paragraph. 

baseline_v2.txt
- Modified the synonym based single feature system to further decrease the number of false negatives. Since our validation showed that the baseline model generated few false negatives but low overall accuracy, we decided to use combine this feature with others and fully utilize its advantages of having low false negatives. We simply added a "delta" so that an article would have to score much higher from the non-Kolata training set than from the Kolata one. 

census-dist-2500-last.txt
- 2500 common last names in the U.S. extracted from the census. This file will be used to build a large stop word list.

census-dist-female-first.txt
- Common female first names in the U.S. extracted from the census. Similar to the census last name file.

census-dist-male-first.txt
- Common female first names in the U.S. extracted from the census. Similar to the census last name file.

modification_justification.txt
- This file contains statistics generated from our single feature prediction model. These statistics show how big of the differences are between the Kolata score and non Kolata score for each test paragraph. The average number helps us decide how much "delta" we should add to further lower false negatives.

single_feature.py
- This file builds our synonym based model. This model effects values words more if 1) it is repeated more, 2) it has more synonyms, and 3) the synonyms frequently occur in the larger corpus (common words that other authors use). So we build a score for every unique word in the testing set against every unique words in the training set. And add the score to get the paragraph score. At last, we compare the score generated against Kolata training set and non Kolata training set. If the difference exceeds the "delta," we have a classification! 
- This file also has scripts that build a larger stop word list from nltk, census and other sources. In addition, we used nltk to build synonym finders and lemmatizers. 
- At the end, we validated against a hold out set in training. 

stopwords.txt
- Very similar to the file we used in class. But we decided to leave some rare symbols in case it represents the author's writing style. 

unique_words.py
- Helper file for us to visualize unique words and their distributions. We experimented with this approach early on and combined with Stanford POS taggers. But we had little luck.
